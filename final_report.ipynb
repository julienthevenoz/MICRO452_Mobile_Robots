{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Basics of Mobile Robotics - 2024\n",
    "\n",
    "## Table of Contents\n",
    "0. [Introduction](#Introduction)\n",
    "1. [Setup](#Partie-1-:-Setup)\n",
    "    - 1.1 : Physical setup\n",
    "    - 1.2 : Code setup\n",
    "2. [Initial tuning](#Partie-2-:-Initial-tuning)\n",
    "    - 2.1 : Wheel speed (differential)\n",
    "3. [Vision](#Partie-2-:-Vision)\n",
    "    - 3.1 : Dynamic lighting adaptation\n",
    "    - 3.2 : Aruko markers\n",
    "        - 3.2.1 : Thymio and goal\n",
    "    - 3.2 : Map resizing\n",
    "4. [Kalmann](#Partie-3-:-Kalmann)\n",
    "    - 4.1 : Theory\n",
    "    - 4.2 : Implementation\n",
    "5. [Global path planning](#Partie-4-:-Global-path-planning)\n",
    "    - 5.1 : Dijkstra\n",
    "6. [Local navigation](#Partie-5-:-Local-navigation)\n",
    "    - 6.1 : Local obstacle detection\n",
    "    - 6.2 : Potential fields\n",
    "7. [Motion control](#Partie-5-:-Motion-control)\n",
    "    - 7.1 : Differential drive\n",
    "    - 7.2 : P-conntroler\n",
    "8. [Demonstrations](#Partie-5-:-emonstrations)\n",
    "9. [Conclusion](#IConclusion)\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Authors : Tifaine Mezencev, Julien, Zhuoran, Christy\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 : Setup\n",
    "\n",
    "### 1.1 : Physical setup\n",
    "\n",
    "```Explication des données utilisées.```\n",
    "\n",
    "A small but determined vessel navigating uncharted waters, its sights set on a glittering treasure at the far edge of the map. Along the way, it must skillfully avoid perilous islands and evade the watchful patrols of navy ships.\n",
    "\n",
    "In this project, we implement global and local navigation for the Thymio robot. The goal is to enable the robot to plot an optimal course toward its destination while dynamically avoiding both static and unexpected obstacles. The key features of our implementation include:\n",
    "\n",
    "- Accurate map creation and feature localization using ArUco markers\n",
    "- Global pathfinding using Dijkstra's algorithm\n",
    "- Seamless connection to the Thymio robot for real-time path execution\n",
    "- Path-following with dynamic adjustment for precision navigation\n",
    "- Emergency handling, including \"Thymio kidnapping\" detection and recovery\n",
    "- Local obstacle avoidance with a potential field method\n",
    "- Robust navigation supported by a Kalman filter in the absence of camera input\n",
    "\n",
    "With this project, we aim to demonstrate how a small robot can overcome big challenges, transforming obstacles into opportunities and bringing our vision of autonomous navigation to life!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 : Code setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 : Initial tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Wheel speed (differential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Vision\n",
    "\n",
    "The Vision.py module has two tasks : run the camera and analyse the frames captured by the camera. This is why the Vision class is actually more of a wrapper around the functionnalities given by the two other classes defined in the vision file, appropriately named Analysis and CameraFeed. \n",
    "\n",
    "\n",
    "Let's dive into Analysis.\n",
    " \n",
    "Given an image, the class has three tasks : pinpoint the thymio, the goal, and the 2D (black) obstacle in a consistent reference frame.  Of course doing this is easier said than done. A getter function of Vision will then be used to access these values and pass them on to the other modules.\n",
    "The first step is defining what is in the map and what is outside the map.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Map\n",
    "\n",
    "We first wanted to use color to differenciate the components of our problem and we painted our map in blue and obstacles in black. Specifically, we tried using a blue color mask to make out the map and pinpoint its four corners. This was relavitely inconsistent however, and we decided to use ArUco markers to make our life easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 : Dynamic lighting adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 : ArUco markers\n",
    "ArUco markers are binary patterns which are unique and have no symmetry. Due to this, they are often used in robotics and computer vision because seeing one markers makes it possible to completely determine the orientation of the camera relative to the marker (and its distance, if the size of the marker is known). They are part of a very convenient library which implements most of the code needed to detect the markers and the according translation and rotation transform matrices.\n",
    "\n",
    "We have 6 markers : one per map corners, and two for the goal and thymio.\n",
    "\n",
    "We wrote a function to find the center point and 2D orientation (defineed as angle between marker top edge and image X-axis). \n",
    "Yes, the aruco library already implements a rotation transform function, yes we forgot to read the docs before starting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 : Thymio and goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 : Map resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Camera management \n",
    "We want the camera to always be running in the background and display the video feed continously (along with whichever debugging displays), independently of what the path planner, control or kalman modules are doing. \n",
    "\n",
    "This is why we use the ```threading``` library, which allows different processes to be run in parallel. The CameraFeed class inherits from the ```threading```.Thread class. \n",
    "Its core method is a while loop that captures a frame, finds its corners, resizes it, detects the Thyimio & goal and (if desired) draws and shows the debugging displays. \n",
    "\n",
    "At the start of the code, the begin() method of the Vision class initializes and runs a CameraFeed thread object, which will continue its work in the background for the rest of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 : Kalmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 : Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 : Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 : Global path planning\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 : Dijkstra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 : Local navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 : Local obstacle detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 : Potential fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 : Motion control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 : Differential drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 : P-conntroler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 : Demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9 : Conclusion\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
